{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import re\n",
    "import ast\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import swifter\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.integrate import quad\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import portion as P\n",
    "import itertools as it\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import namedtuple\n",
    "from pprint import pprint\n",
    "from pytictoc import TicToc\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from my_utils import *\n",
    "\n",
    "# Configure display options\n",
    "# pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Set plot style\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DataLoader: Single Radio Example\n",
    "# dates = data_loader(query_dates=True)\n",
    "\n",
    "# selected_dates = [s for s in dates if s >= '2023-09-12']\n",
    "# # excluded_dates = []\n",
    "# # selected_exps = []\n",
    "# # excluded_exps = ['Modem_Action_Test', 'Control_Group', 'Control_Group2', 'Control_Group3']\n",
    "# # selected_routes = ['BR']\n",
    "# # excluded_routes = []\n",
    "# filepaths = data_loader(mode='sr', selected_dates=selected_dates)\n",
    "\n",
    "# filepath = filepaths[0]\n",
    "# pprint(filepath)\n",
    "\n",
    "# ho_df = pd.read_csv(filepath[0], parse_dates=['start', 'end'])\n",
    "# df = pd.read_csv(filepath[1], parse_dates=['Timestamp'])[['seq', 'Timestamp', 'lost', 'excl', 'latency']]\n",
    "# df, ho_df, empty_data = data_aligner(df, ho_df)\n",
    "\n",
    "# display(df)\n",
    "\n",
    "\n",
    "# # DataLoader: Dual Radio Example\n",
    "# dates = data_loader(query_dates=True)\n",
    "\n",
    "# selected_dates = [s for s in dates if s >= '2023-09-12']\n",
    "# # excluded_dates = []\n",
    "# # selected_exps = []\n",
    "# # excluded_exps = ['Modem_Action_Test', 'Control_Group', 'Control_Group2', 'Control_Group3']\n",
    "# # selected_routes = ['BR']\n",
    "# # excluded_routes = []\n",
    "# filepaths = data_loader(mode='dr', selected_dates=selected_dates)\n",
    "\n",
    "# filepath = filepaths[0]\n",
    "# pprint(filepath)\n",
    "\n",
    "# ho_df1 = pd.read_csv(filepath[0][0], parse_dates=['start', 'end'])\n",
    "# ho_df2 = pd.read_csv(filepath[1][0], parse_dates=['start', 'end'])\n",
    "# df1 = pd.read_csv(filepath[0][1], parse_dates=['Timestamp'])[['seq', 'Timestamp', 'lost', 'excl', 'latency']]\n",
    "# df2 = pd.read_csv(filepath[1][1], parse_dates=['Timestamp'])[['seq', 'Timestamp', 'lost', 'excl', 'latency']]\n",
    "# df, df1, df2, ho_df1, ho_df2, empty_data = data_consolidator(df1, df2, ho_df1, ho_df2)\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(x, y, ratio=0.5):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x, y (datetime.datetime): x < y\n",
    "        ratio (float): a decimal numeral in a range [0, 1]; 0 means break at x, 1 means break at y.\n",
    "    Returns:\n",
    "        (datetime.datetime): breakpoint of interpolation\n",
    "    \"\"\"\n",
    "    return x + (y - x) * ratio\n",
    "\n",
    "def mean_downsample(data, sample_size=100000):\n",
    "    \"\"\"\n",
    "    平均下採樣函數\n",
    "    \n",
    "    Args:\n",
    "    data: 原始數據的列表\n",
    "    sample_size: 下採樣後的樣本大小\n",
    "    \n",
    "    Returns:\n",
    "    downsampled_data: 下採樣後的數據列表\n",
    "    \"\"\"\n",
    "    chunk_size = len(data) // sample_size\n",
    "    if chunk_size == 0:\n",
    "        return data\n",
    "    downsampled_data = [sum(data[i:i+chunk_size]) / chunk_size for i in range(0, len(data), chunk_size)]\n",
    "    return downsampled_data\n",
    "\n",
    "def median_downsample(data, sample_size=100000):\n",
    "    \"\"\"\n",
    "    中位數下採樣函數\n",
    "    \n",
    "    Args:\n",
    "    data: 原始數據的列表\n",
    "    sample_size: 下採樣後的樣本大小\n",
    "    \n",
    "    Returns:\n",
    "    downsampled_data: 下採樣後的數據列表\n",
    "    \"\"\"\n",
    "    chunk_size = len(data) // sample_size\n",
    "    if chunk_size == 0:\n",
    "        return data\n",
    "    downsampled_data = []\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        chunk = data[i:i+chunk_size]\n",
    "        median_index = len(chunk) // 2\n",
    "        median_value = np.median(chunk)\n",
    "        downsampled_data.append(median_value)\n",
    "    return downsampled_data\n",
    "\n",
    "def total_area_kde(kde, lower_bound=-np.inf, upper_bound=np.inf):\n",
    "    # 定義積分函數\n",
    "    def integrand(x):\n",
    "        return kde(x)\n",
    "    total_area, _ = quad(integrand, lower_bound, upper_bound)\n",
    "    return total_area\n",
    "\n",
    "def total_area_histogram_with_centers(x_centers, heights, bin_width):\n",
    "    # 計算每個 bin 的面積並相加\n",
    "    total_area = bin_width * sum(heights)\n",
    "    return total_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class: Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Profile():\n",
    "    def __init__(self, filepaths, model_name='Trial',\n",
    "                 scope_agg=None, scope=None, sp_columns=['type'], ts_column='Timestamp',\n",
    "                 metrics=['dl_lost', 'dl_excl', 'ul_lost', 'ul_excl']):\n",
    "        \n",
    "        # Initialize instance variables\n",
    "        self.filepaths = copy.deepcopy(filepaths)\n",
    "        self.model_name = model_name\n",
    "        if scope_agg is None:\n",
    "            if scope is None:\n",
    "                scope = {\n",
    "                    **{key: (-5.0, 5.0) for key in ['LTEH', 'ENBH', 'MCGH', 'MNBH', 'SCGM', 'SCGA', 'SCGR-I', 'SCGR-II', 'SCGC-I', 'SCGC-II']},\n",
    "                    **{key: (-10.0, 10.0) for key in ['SCGF', 'MCGF', 'NASR']}, \n",
    "                    'Stable': (-1.0, 1.0)\n",
    "                }\n",
    "            self.scope_agg = { mode_mets: scope.copy() for mode_mets in metrics }   \n",
    "        else:\n",
    "            self.scope_agg = copy.deepcopy(scope_agg)\n",
    "        self.sp_columns = sp_columns[:]\n",
    "        self.ts_column = ts_column\n",
    "        self.metrics = metrics[:]\n",
    "        self.Container = { mode_mets: { tag: { 'dist_table': [],\n",
    "                                               'relative_loex_timestamp': [],\n",
    "                                               'relative_timestamp': [],\n",
    "                                               'interruption_time': [],\n",
    "                                               'trigger_loex': [],\n",
    "                                               'event_count': [] } \n",
    "                                        for tag in self.scope_agg[mode_mets].keys() }\n",
    "                                        for mode_mets in metrics }\n",
    "        self.Profile = { mode_mets: { tag: { 'dist_table': None,\n",
    "                                             'relative_loex_timestamp': [],\n",
    "                                             'relative_timestamp': [],\n",
    "                                             'interruption_time': [],\n",
    "                                             'trigger_loex': [],\n",
    "                                             'event_count': 0 } \n",
    "                                        for tag in self.scope_agg[mode_mets].keys() }\n",
    "                                        for mode_mets in metrics }\n",
    "        self.scope_models = copy.deepcopy(self.scope_agg)\n",
    "        self.hist_models = { mode_mets: { tag: None for tag in self.scope_agg[mode_mets].keys() } for mode_mets in metrics }\n",
    "        self.kde_models = { mode_mets: { tag: (None, None) for tag in self.scope_agg[mode_mets].keys() } for mode_mets in metrics }\n",
    "        self.prob_models = { mode_mets: { tag: None for tag in self.scope_agg[mode_mets].keys() } for mode_mets in metrics }\n",
    "        \n",
    "        # Construct profiles\n",
    "        # self.construct_profile()\n",
    "        # self.modeling()\n",
    "    \n",
    "    \n",
    "    def create_instance(self, df, center, interval, mets='lost', w_size=0.01):\n",
    "        df = df[(df[self.ts_column] >= interval.lower) & (df[self.ts_column] < interval.upper)].copy().reset_index(drop=True)\n",
    "        \n",
    "        # Relative window converted from timestamp\n",
    "        df['relative_time'] = (df['Timestamp'] - center).dt.total_seconds()\n",
    "        df['window_id'] = ((df['relative_time'] + w_size / 2) // w_size) * w_size  # 四捨五入\n",
    "        \n",
    "        if mets == 'lost':\n",
    "            RATE_TYPE = 'PLR'\n",
    "            loex_df = df[df['lost']].copy()\n",
    "            ts_group = df.groupby(['window_id'])\n",
    "            table = ts_group.agg({'lost': ['count','sum'], 'Timestamp': ['first']}).reset_index()\n",
    "        elif mets == 'excl':\n",
    "            RATE_TYPE = 'ELR'\n",
    "            df['excl_exact'] = df['excl'] & ~df['lost']\n",
    "            loex_df = df[df['excl_exact']].copy()\n",
    "            ts_group = df.groupby(['window_id'])\n",
    "            table = ts_group.agg({'excl_exact': ['count','sum'], 'Timestamp': ['first']}).reset_index()\n",
    "        \n",
    "        table.columns = ['window_id','tx_count',mets,'Timestamp']\n",
    "        \n",
    "        return table, loex_df['relative_time'].to_list(), df['relative_time'].to_list()\n",
    "        # return table, loex_df['relative_time'].to_numpy()\n",
    "    \n",
    "    \n",
    "    def setup_profile(self, df, ho_df, mode, mets, scope):\n",
    "        # Initialize \"Register\"\n",
    "        Register = { tag: { 'dist_table': [],\n",
    "                            'relative_loex_timestamp': [],\n",
    "                            'relative_timestamp': [],\n",
    "                            'interruption_time': [],\n",
    "                            'trigger_loex': [] } for tag in scope.keys() }\n",
    "        this_df = df.copy()\n",
    "        \n",
    "        for i, row in ho_df.iterrows():\n",
    "            prior_row = ho_df.iloc[i-1] if i != 0 else None\n",
    "            post_row = ho_df.iloc[i+1] if i != len(ho_df) - 1 else None\n",
    "\n",
    "            # Peek the next event to avoid HO overlapping with handoverFailure (skip!!)\n",
    "            if i != len(ho_df) - 1 and pd.notna(row.end) and row.end > post_row.start:\n",
    "                # print('Overlapping event occurs!!')\n",
    "                # print(i, row['start'], row['end'], row['type'], row['cause'])\n",
    "                # print(i+1, post_row['start'], post_row['end'], post_row['type'], post_row['cause'])\n",
    "                continue\n",
    "            \n",
    "            # Set prior event if the prior loop is skipped\n",
    "            if i != 0 and pd.notna(prior_row.end) and prior_row.end > row.start:\n",
    "                prior_row = ho_df.iloc[i-2] if i > 1 else None\n",
    "            \n",
    "            # Basic information of the current row\n",
    "            tag = '_'.join([s for s in row[self.sp_columns] if pd.notna(s)])  # specific column name\n",
    "            start_ts, end_ts = row['start'], row['end']  # handover start/end time\n",
    "            interruption_time = (end_ts - start_ts).total_seconds() if pd.notna(end_ts) else 0  # handover interruption time\n",
    "            \n",
    "            # Set simple left/right bounds\n",
    "            current_left_bound = start_ts + pd.Timedelta(seconds=(scope[tag][0]))\n",
    "            current_right_bound = start_ts + pd.Timedelta(seconds=(scope[tag][1]))\n",
    "            \n",
    "            # Set left/right bounds to avoid event overlapping with each other\n",
    "            if prior_row is not None:\n",
    "                prior_tag = '_'.join([s for s in prior_row[self.sp_columns] if pd.notna(s)])\n",
    "                prior_right_bound = prior_row['start'] + pd.Timedelta(seconds=(scope[prior_tag][1]))\n",
    "                if pd.notna(prior_row['end']):\n",
    "                    # left = prior_row['end'] + (start_ts - prior_row['end']) / 2\n",
    "                    left_bound = min(max(current_left_bound, Profile.interpolate(prior_right_bound, current_left_bound), prior_row['end']), start_ts)\n",
    "                else:\n",
    "                    # left = prior_row['start'] + (start_ts - prior_row['start']) / 2\n",
    "                    left_bound = min(max(current_left_bound, Profile.interpolate(prior_right_bound, current_left_bound), prior_row['start']), start_ts)\n",
    "            else:\n",
    "                # left_bound = pd.Timestamp.min\n",
    "                left_bound = current_left_bound\n",
    "            \n",
    "            if post_row is not None:\n",
    "                post_tag = '_'.join([s for s in post_row[self.sp_columns] if pd.notna(s)])\n",
    "                post_left_bound = post_row['start'] + pd.Timedelta(seconds=(scope[post_tag][0]))\n",
    "                if pd.notna(end_ts):\n",
    "                    # right = end_ts + (post_row['start'] - end_ts) / 2\n",
    "                    right_bound = max(min(current_right_bound, Profile.interpolate(current_right_bound, post_left_bound), post_row['start']), end_ts)\n",
    "                else:\n",
    "                    # right = start_ts + (post_row['start'] - start_ts) / 2\n",
    "                    right_bound = max(min(current_right_bound, Profile.interpolate(current_right_bound, post_left_bound), post_row['start']), start_ts)\n",
    "            else:\n",
    "                # right_bound = pd.Timestamp.max\n",
    "                right_bound = current_right_bound\n",
    "            \n",
    "            # interval = P.closed(max(start_ts+pd.Timedelta(seconds=scope[tag][0]), left_bound), min(start_ts+pd.Timedelta(seconds=scope[tag][1]), right_bound))\n",
    "            interval = P.closed(left_bound, right_bound)\n",
    "\n",
    "            # Consider the stable duration before an event starts\n",
    "            stable_df = this_df[this_df[self.ts_column] < interval.lower].copy()\n",
    "            stable_df['Timestamp_to_second'] = stable_df['Timestamp'].dt.floor('S')\n",
    "            \n",
    "            if not stable_df.empty:\n",
    "                unique_timestamps = stable_df['Timestamp_to_second'].unique()\n",
    "                \n",
    "                tmp_df = stable_df.copy()\n",
    "                for ts in unique_timestamps:\n",
    "                    stable_center = ts + pd.Timedelta(seconds=0.5)\n",
    "                    stable_interval = P.closed(ts, min(ts + pd.Timedelta(seconds=1), interval.lower))\n",
    "                    \n",
    "                    # Create an instance of stable profile\n",
    "                    # dist_table, relative_loex_timestamp = self.create_instance(tmp_df.copy(), stable_center, stable_interval, mets=mets)\n",
    "                    dist_table, relative_loex_timestamp, relative_timestamp = self.create_instance(tmp_df.copy(), stable_center, stable_interval, mets=mets)\n",
    "                    \n",
    "                    # if len(relative_loex_timestamp):\n",
    "                    #     display(dist_table)\n",
    "                    #     print('Stable', len(relative_loex_timestamp), relative_loex_timestamp)\n",
    "                    \n",
    "                    # Feed into \"Register\"\n",
    "                    if len(relative_loex_timestamp):\n",
    "                        Register['Stable']['trigger_loex'].append(1)\n",
    "                        Register['Stable']['dist_table'].append(dist_table)\n",
    "                        Register['Stable']['relative_loex_timestamp'] += relative_loex_timestamp\n",
    "                        # Register['Stable']['relative_loex_timestamp'] = np.concatenate((Register['Stable']['relative_loex_timestamp'], relative_loex_timestamp))\n",
    "                    else:\n",
    "                        Register['Stable']['trigger_loex'].append(0)\n",
    "                    Register['Stable']['interruption_time'].append((stable_interval.upper - stable_interval.lower).total_seconds())\n",
    "                    Register['Stable']['relative_timestamp'] += relative_timestamp\n",
    "                    \n",
    "                    # Update dataframe to accelerate\n",
    "                    tmp_df = tmp_df[tmp_df[self.ts_column] >= ts + pd.Timedelta(seconds=1)]\n",
    "            \n",
    "            # Create an instance of handover profile\n",
    "            # dist_table, relative_loex_timestamp = self.create_instance(this_df.copy(), start_ts, interval, mets=mets)\n",
    "            dist_table, relative_loex_timestamp, relative_timestamp = self.create_instance(this_df.copy(), start_ts, interval, mets=mets)\n",
    "            \n",
    "            # if len(relative_loex_timestamp):\n",
    "            #     display(dist_table)\n",
    "            #     print(tag, len(relative_loex_timestamp), relative_loex_timestamp)\n",
    "            \n",
    "            # Feed into \"Register\"\n",
    "            if len(relative_loex_timestamp):\n",
    "                Register[tag]['trigger_loex'].append(1)\n",
    "                Register[tag]['dist_table'].append(dist_table)\n",
    "                Register[tag]['relative_loex_timestamp'] += relative_loex_timestamp\n",
    "                # Register[tag]['relative_loex_timestamp'] = np.concatenate((Register[tag]['relative_loex_timestamp'], relative_loex_timestamp))\n",
    "            else:\n",
    "                Register[tag]['trigger_loex'].append(0)\n",
    "            Register[tag]['interruption_time'].append(interruption_time)\n",
    "            Register[tag]['relative_timestamp'] += relative_timestamp\n",
    "            \n",
    "            # Update dataframe to accelerate the speed\n",
    "            this_df = this_df[this_df[self.ts_column] >= interval.upper].copy()\n",
    "\n",
    "        # Consider the stable duration after the last event ends\n",
    "        stable_df = this_df.copy()\n",
    "        stable_df['Timestamp_to_second'] = stable_df['Timestamp'].dt.floor('S')\n",
    "\n",
    "        if not stable_df.empty:\n",
    "            unique_timestamps = stable_df['Timestamp_to_second'].unique()\n",
    "            \n",
    "            tmp_df = stable_df.copy()\n",
    "            for ts in unique_timestamps:\n",
    "                stable_center = ts + pd.Timedelta(seconds=0.5)\n",
    "                stable_interval = P.closed(ts, ts + pd.Timedelta(seconds=1))\n",
    "                \n",
    "                # Create an instance of stable profile\n",
    "                # dist_table, relative_loex_timestamp = self.create_instance(tmp_df.copy(), stable_center, stable_interval, mets=mets)\n",
    "                dist_table, relative_loex_timestamp, relative_timestamp = self.create_instance(tmp_df.copy(), stable_center, stable_interval, mets=mets)\n",
    "                \n",
    "                # if len(relative_loex_timestamp):\n",
    "                #     display(dist_table)\n",
    "                #     print('Stable', len(relative_loex_timestamp), relative_loex_timestamp)\n",
    "                \n",
    "                # Feed into \"Register\"\n",
    "                if len(relative_loex_timestamp):\n",
    "                    Register['Stable']['trigger_loex'].append(1)\n",
    "                    Register['Stable']['dist_table'].append(dist_table)\n",
    "                    Register['Stable']['relative_loex_timestamp'] += relative_loex_timestamp\n",
    "                    # Register['Stable']['relative_loex_timestamp'] = np.concatenate((Register['Stable']['relative_loex_timestamp'], relative_loex_timestamp))\n",
    "                else:\n",
    "                    Register['Stable']['trigger_loex'].append(0)\n",
    "                Register['Stable']['interruption_time'].append((stable_interval.upper - stable_interval.lower).total_seconds())\n",
    "                Register['Stable']['relative_timestamp'] += relative_timestamp\n",
    "                \n",
    "                # Update dataframe to accelerate\n",
    "                tmp_df = tmp_df[tmp_df[self.ts_column] >= ts + pd.Timedelta(seconds=1)]\n",
    "        \n",
    "        return Register\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def dist_aggregate(tables, mode, mets):\n",
    "        if mets == 'lost':\n",
    "            RATE_TYPE = 'PLR'\n",
    "        elif mets == 'excl':\n",
    "            RATE_TYPE = 'ELR'\n",
    "        \n",
    "        table = pd.DataFrame(columns=['window_id','tx_count',mets])\n",
    "        table[mets] = table[mets].astype('Int32')\n",
    "        table['window_id'] = table['window_id'].astype('float32')\n",
    "        table['tx_count'] = table['tx_count'].astype('Int32')\n",
    "        \n",
    "        tables = [t for t in tables if t is not None]\n",
    "        for this_table in tables:\n",
    "            table = table.merge(this_table, on=['window_id'], how='outer').fillna(0)\n",
    "            table['tx_count'] = table['tx_count_x'] + table['tx_count_y']\n",
    "            table[mets] = table[f'{mets}_x'] + table[f'{mets}_y']\n",
    "            table = table[['window_id','tx_count',mets]]\n",
    "        \n",
    "        table[RATE_TYPE] = table[mets] / (table['tx_count'] + 1e-9) * 100\n",
    "        table[RATE_TYPE] = table[RATE_TYPE].astype('float32')\n",
    "        \n",
    "        table = table[['window_id','tx_count',mets,RATE_TYPE]].copy().sort_values(by=['window_id']).reset_index(drop=True)\n",
    "        return table\n",
    "    \n",
    "    \n",
    "    def construct_profile(self):\n",
    "        n = len(self.filepaths)\n",
    "        \n",
    "        for i, filepath in enumerate(self.filepaths):\n",
    "            \n",
    "            if i > 1:\n",
    "                break\n",
    "            \n",
    "            for s in filepath[:3]:\n",
    "                print(f'{i+1}/{n}', s)\n",
    "            \n",
    "            dl_df, ul_df = None, None\n",
    "            ho_df = pd.read_csv(filepath[0], parse_dates=['start', 'end'])\n",
    "            if ho_df.empty:\n",
    "                print('******** Empty RRC Data ********')\n",
    "                continue\n",
    "            \n",
    "            for mode_mets in self.metrics:\n",
    "                mode, mets = mode_mets[:2], mode_mets[-4:]\n",
    "                scope = self.scope_agg[mode_mets]\n",
    "                \n",
    "                if mode == 'dl':\n",
    "                    if dl_df is None:\n",
    "                        dl_df = pd.read_csv(filepath[1], parse_dates=['Timestamp'])[['seq', 'Timestamp', 'lost', 'excl', 'latency']]\n",
    "                    df = dl_df.copy()\n",
    "                elif mode == 'ul':\n",
    "                    if ul_df is None:\n",
    "                        ul_df = pd.read_csv(filepath[2], parse_dates=['Timestamp'])[['seq', 'Timestamp', 'lost', 'excl', 'latency']]\n",
    "                    df = ul_df.copy()\n",
    "                \n",
    "                ho_df = pd.read_csv(filepath[0], parse_dates=['start', 'end'])\n",
    "                df, ho_df, empty_data = data_aligner(df, ho_df)\n",
    "                \n",
    "                if empty_data:\n",
    "                    print('******** Empty Data:', mode_mets, '********')\n",
    "                    continue\n",
    "                \n",
    "                Register = self.setup_profile(df, ho_df, mode, mets, scope)\n",
    "                \n",
    "                # Append \"Register\" for each trace\n",
    "                for tag in scope.keys():\n",
    "                    # if len(Register[tag]['interruption_time']) == 0:\n",
    "                    #     continue\n",
    "                    \n",
    "                    table = Profile.dist_aggregate(Register[tag]['dist_table'], mode, mets)\n",
    "                    self.Container[mode_mets][tag]['dist_table'].append(table)\n",
    "                    self.Container[mode_mets][tag]['relative_loex_timestamp'].append(Register[tag]['relative_loex_timestamp'])\n",
    "                    self.Container[mode_mets][tag]['relative_timestamp'].append(Register[tag]['relative_timestamp'])\n",
    "                    self.Container[mode_mets][tag]['trigger_loex'].append(Register[tag]['trigger_loex'])\n",
    "                    self.Container[mode_mets][tag]['interruption_time'].append(Register[tag]['interruption_time'])\n",
    "                    self.Container[mode_mets][tag]['event_count'].append(len(Register[tag]['interruption_time']))\n",
    "        \n",
    "        for mode_mets in self.metrics:\n",
    "            mode, mets = mode_mets[:2], mode_mets[-4:]\n",
    "            scope = self.scope_agg[mode_mets]\n",
    "            \n",
    "            for tag in scope.keys():\n",
    "                self.Profile[mode_mets][tag]['dist_table'] = Profile.dist_aggregate(self.Container[mode_mets][tag]['dist_table'], mode, mets)\n",
    "                \n",
    "                # self.Profile[mode_mets][tag]['relative_loex_timestamp'] = self.Container[mode_mets][tag]['relative_loex_timestamp']\n",
    "                data = []\n",
    "                for lst in self.Container[mode_mets][tag]['relative_loex_timestamp']:\n",
    "                    data += lst\n",
    "                self.Profile[mode_mets][tag]['relative_loex_timestamp'] = Profile.mean_downsample(sorted(data))\n",
    "                self.Container[mode_mets][tag]['relative_loex_timestamp'] = []\n",
    "                \n",
    "                # self.Profile[mode_mets][tag]['relative_timestamp'] = self.Container[mode_mets][tag]['relative_timestamp']\n",
    "                data = []\n",
    "                for lst in self.Container[mode_mets][tag]['relative_timestamp']:\n",
    "                    data += lst\n",
    "                self.Profile[mode_mets][tag]['relative_timestamp'] = Profile.mean_downsample(sorted(data))\n",
    "                self.Container[mode_mets][tag]['relative_timestamp'] = []\n",
    "                \n",
    "                # self.Profile[mode_mets][tag]['trigger_loex'] = self.Container[mode_mets][tag]['trigger_loex']\n",
    "                for lst in self.Container[mode_mets][tag]['trigger_loex']:\n",
    "                    self.Profile[mode_mets][tag]['trigger_loex'] += lst\n",
    "                \n",
    "                # self.Profile[mode_mets][tag]['interruption_time'] = self.Container[mode_mets][tag]['interruption_time']\n",
    "                for lst in self.Container[mode_mets][tag]['interruption_time']:\n",
    "                    self.Profile[mode_mets][tag]['interruption_time'] += lst\n",
    "                \n",
    "                # self.Profile[mode_mets][tag]['event_count'] = self.Container[mode_mets][tag]['event_count']\n",
    "                self.Profile[mode_mets][tag]['event_count'] += sum(self.Container[mode_mets][tag]['event_count'])\n",
    "                \n",
    "                del data\n",
    "    \n",
    "    \n",
    "    def modeling(self, sd_factor=3, w_size=0.01):\n",
    "        for i, mode_mets in enumerate(self.metrics):\n",
    "            mode, mets = mode_mets[:2], mode_mets[-4:]\n",
    "            if mets == 'lost':\n",
    "                RATE_TYPE = 'PLR'\n",
    "            elif mets == 'excl':\n",
    "                RATE_TYPE = 'ELR'\n",
    "            \n",
    "            # if i > 0:\n",
    "            #     break\n",
    "            \n",
    "            scope = self.scope_agg[mode_mets]\n",
    "            for tag in scope.keys():\n",
    "                # print(tag)\n",
    "                left_bound, right_bound = scope[tag]\n",
    "                table = self.Profile[mode_mets][tag]['dist_table']\n",
    "                loex_data = self.Profile[mode_mets][tag]['relative_loex_timestamp']\n",
    "                xmit_data = self.Profile[mode_mets][tag]['relative_timestamp']\n",
    "                trigger_lst = self.Profile[mode_mets][tag]['trigger_loex']\n",
    "                \n",
    "                self.hist_models[mode_mets][tag] = table.copy()\n",
    "                \n",
    "                if len(trigger_lst) == 0:\n",
    "                    continue\n",
    "                \n",
    "                estimated_p = sum(trigger_lst) / len(trigger_lst)\n",
    "                self.prob_models[mode_mets][tag] = estimated_p\n",
    "                \n",
    "                if len(loex_data) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if tag == 'Stable':\n",
    "                    mean = 0\n",
    "                    left_bound, right_bound = -0.5, 0.5\n",
    "                else:\n",
    "                    loex_table = table[table[mets] > 0].reset_index(drop=True)\n",
    "                    mean, std_dev = np.mean(loex_data), np.std(loex_data)\n",
    "                    left_bound = math.floor(max(left_bound, mean - sd_factor * std_dev, loex_table.iloc[0]['window_id']) * 10) / 10\n",
    "                    right_bound = math.ceil(min(right_bound, mean + sd_factor * std_dev, loex_table.iloc[-1]['window_id']) * 10) / 10\n",
    "                \n",
    "                self.scope_models[mode_mets][tag] = (left_bound, right_bound)\n",
    "                \n",
    "                x = np.asarray(table['window_id'], dtype=np.float64)\n",
    "                y = np.asarray(table[RATE_TYPE], dtype=np.float64)\n",
    "                \n",
    "                # 計算直方圖的面積\n",
    "                hist_area = Profile.total_area_histogram_with_centers(x, y, w_size)\n",
    "                # print(\"Total area of histogram:\", hist_area)\n",
    "                \n",
    "                # kde1 = gaussian_kde(loex_data)\n",
    "                # kde2 = gaussian_kde(xmit_data)\n",
    "                # def kde(x):\n",
    "                #     kde2_values = kde2(x)\n",
    "                #     # 檢查 kde2 是否為零，如果是則返回一個小的非零值\n",
    "                #     kde2_values[kde2_values == 0] = 1\n",
    "                #     return kde1(x) / kde2_values\n",
    "                kde = gaussian_kde(loex_data)\n",
    "                \n",
    "                # 計算 KDE 下的總面積（無窮積分）\n",
    "                # kde_area = Profile.total_area_kde(kde)\n",
    "                # 計算 KDE 下的總面積（只計算正負2.5個標準差內的點，理論上 scalar 會稍微高估，但不會太多）\n",
    "                kde_area = Profile.total_area_kde(kde, left_bound, right_bound)\n",
    "                # print(\"Total area under KDE:\", kde_area)\n",
    "                \n",
    "                scalar = hist_area / kde_area\n",
    "                # print(\"Scalar:\", scalar)\n",
    "                \n",
    "                self.kde_models[mode_mets][tag] = (scalar, kde)\n",
    "    \n",
    "    \n",
    "    def plot(self, sd_factor=3):\n",
    "        for i, mode_mets in enumerate(self.metrics):\n",
    "            mode, mets = mode_mets[:2], mode_mets[-4:]\n",
    "            if mets == 'lost':\n",
    "                RATE_TYPE = 'PLR'\n",
    "            elif mets == 'excl':\n",
    "                RATE_TYPE = 'ELR'\n",
    "            \n",
    "            # if i > 0:\n",
    "            #     break\n",
    "            \n",
    "            scope = self.scope_agg[mode_mets]\n",
    "            for tag in scope.keys():\n",
    "                print('===================================================================================')\n",
    "                print(tag)\n",
    "                \n",
    "                loex_data = self.Profile[mode_mets][tag]['relative_loex_timestamp']\n",
    "                xmit_data = self.Profile[mode_mets][tag]['relative_timestamp']\n",
    "                trigger_lst = self.Profile[mode_mets][tag]['trigger_loex']\n",
    "                \n",
    "                left_bound, right_bound = self.scope_models[mode_mets][tag]\n",
    "                table = self.hist_models[mode_mets][tag]\n",
    "                scalar, kde = self.kde_models[mode_mets][tag]\n",
    "                \n",
    "                if len(loex_data) == 0:\n",
    "                    continue\n",
    "                \n",
    "                fig, ax = plt.subplots(figsize=(6, 4))\n",
    "                \n",
    "                x = np.asarray(table['window_id'], dtype=np.float64)\n",
    "                y = np.asarray(table[RATE_TYPE], dtype=np.float64)\n",
    "                ax.bar(x, y, label='hist', width=0.01, alpha=0.97)\n",
    "                \n",
    "                # ax = ax.twinx()\n",
    "                \n",
    "                x = np.linspace(min(xmit_data), max(xmit_data), 1000)\n",
    "                density = scalar * kde(x)\n",
    "                \n",
    "                ax.fill_between(x, density, label='KDE', color='tab:orange', alpha=0.45, linewidth=0)\n",
    "        \n",
    "                # find the scope and boundaries\n",
    "                # ax.axvline(x=mean, color='red', linestyle='--', label='Mean')\n",
    "                ax.axvline(x=left_bound, color='blue', linestyle='--', label=f'-{sd_factor} Std')\n",
    "                ax.axvline(x=right_bound, color='blue', linestyle='--', label=f'+{sd_factor} Std')\n",
    "                \n",
    "                bottom, top = ax.get_ylim()\n",
    "                ax.text(left_bound, bottom-0.05*(top-bottom), '{:.1f}'.format(left_bound), ha='center', fontweight='bold', fontsize=10, color='blue')\n",
    "                ax.text(right_bound, bottom-0.05*(top-bottom), '{:.1f}'.format(right_bound), ha='center', fontweight='bold', fontsize=10, color='blue')\n",
    "                \n",
    "                if mode == 'dl':\n",
    "                    if mets == 'lost':\n",
    "                        ax.set_title(f'Downlink PLR: {tag}')\n",
    "                    elif mets == 'excl':\n",
    "                        ax.set_title(f'Downlink ELR: {tag}')\n",
    "                elif mode == 'ul':\n",
    "                    if mets == 'lost':\n",
    "                        ax.set_title(f'Uplink PLR: {tag}')\n",
    "                    elif mets == 'excl':\n",
    "                        ax.set_title(f'Uplink ELR: {tag}')\n",
    "                \n",
    "                if mets == 'lost':\n",
    "                    ax.set_ylabel('Packet Loss Rate (%)')\n",
    "                elif mets == 'excl':\n",
    "                    ax.set_ylabel('Excessive Latency Rate (%)')\n",
    "                ax.set_xlabel('Relative Timestamp (sec)')\n",
    "                \n",
    "                ax.legend()\n",
    "                \n",
    "                plt.gcf().autofmt_xdate()\n",
    "                plt.show()\n",
    "    \n",
    "    \n",
    "    def save_models(self):\n",
    "        with open(f'{self.model_name}_kde_models.pkl', 'wb') as f:\n",
    "            pickle.dump(self.kde_models, f)\n",
    "        with open(f'{self.model_name}_hist_models.pkl', 'wb') as f:\n",
    "            pickle.dump(self.hist_models, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(f'{self.model_name}_scope_models.pkl', 'wb') as f:\n",
    "            pickle.dump(self.scope_models, f)\n",
    "        with open(f'{self.model_name}_sr_prob_models.pkl', 'wb') as f:\n",
    "            pickle.dump(self.prob_models, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#01/data/handover_info_log.csv',\n",
      " '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#01/data/udp_dnlk_loss_latency.csv',\n",
      " '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#01/data/udp_uplk_loss_latency.csv',\n",
      " '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#01/data/diag_log_sm00_2023-09-12_13-34-15_rrc.csv',\n",
      " '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#01/data/diag_log_sm00_2023-09-12_13-34-15_ml1.csv',\n",
      " '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#01/data/diag_log_sm00_2023-09-12_13-34-15_nr_ml1.csv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>lost</th>\n",
       "      <th>excl</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2501</td>\n",
       "      <td>2023-09-12 13:34:16.245625</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.015184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2502</td>\n",
       "      <td>2023-09-12 13:34:16.247625</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2503</td>\n",
       "      <td>2023-09-12 13:34:16.249625</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.016496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2504</td>\n",
       "      <td>2023-09-12 13:34:16.251626</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.014495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2505</td>\n",
       "      <td>2023-09-12 13:34:16.253626</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.012495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417486</th>\n",
       "      <td>1419987</td>\n",
       "      <td>2023-09-12 14:21:31.350104</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.013385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417487</th>\n",
       "      <td>1419988</td>\n",
       "      <td>2023-09-12 14:21:31.352104</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.009389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417488</th>\n",
       "      <td>1419989</td>\n",
       "      <td>2023-09-12 14:21:31.354104</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.011389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417489</th>\n",
       "      <td>1419990</td>\n",
       "      <td>2023-09-12 14:21:31.356104</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.013389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417490</th>\n",
       "      <td>1419991</td>\n",
       "      <td>2023-09-12 14:21:31.358104</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.009347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1417491 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             seq                  Timestamp   lost   excl   latency\n",
       "0           2501 2023-09-12 13:34:16.245625  False  False  0.015184\n",
       "1           2502 2023-09-12 13:34:16.247625  False  False  0.013184\n",
       "2           2503 2023-09-12 13:34:16.249625  False  False  0.016496\n",
       "3           2504 2023-09-12 13:34:16.251626  False  False  0.014495\n",
       "4           2505 2023-09-12 13:34:16.253626  False  False  0.012495\n",
       "...          ...                        ...    ...    ...       ...\n",
       "1417486  1419987 2023-09-12 14:21:31.350104  False  False -0.013385\n",
       "1417487  1419988 2023-09-12 14:21:31.352104  False  False -0.009389\n",
       "1417488  1419989 2023-09-12 14:21:31.354104  False  False -0.011389\n",
       "1417489  1419990 2023-09-12 14:21:31.356104  False  False -0.013389\n",
       "1417490  1419991 2023-09-12 14:21:31.358104  False  False -0.009347\n",
       "\n",
       "[1417491 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DataLoader: Single Radio Example\n",
    "dates = data_loader(query_dates=True)\n",
    "\n",
    "selected_dates = [s for s in dates if s >= '2023-09-12']\n",
    "# excluded_dates = []\n",
    "# selected_exps = []\n",
    "# excluded_exps = ['Modem_Action_Test', 'Control_Group', 'Control_Group2', 'Control_Group3']\n",
    "# selected_routes = ['BR']\n",
    "# excluded_routes = []\n",
    "filepaths = data_loader(mode='sr', selected_dates=selected_dates)\n",
    "\n",
    "filepath = filepaths[0]\n",
    "pprint(filepath)\n",
    "\n",
    "ho_df = pd.read_csv(filepath[0], parse_dates=['start', 'end'])\n",
    "df = pd.read_csv(filepath[1], parse_dates=['Timestamp'])[['seq', 'Timestamp', 'lost', 'excl', 'latency']]\n",
    "df, ho_df, empty_data = data_aligner(df, ho_df)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#01/data/handover_info_log.csv',\n",
       "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#01/data/udp_dnlk_loss_latency.csv',\n",
       "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#01/data/udp_uplk_loss_latency.csv',\n",
       "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#01/data/diag_log_sm00_2023-09-12_13-34-15_rrc.csv',\n",
       "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#01/data/diag_log_sm00_2023-09-12_13-34-15_ml1.csv',\n",
       "  '/Users/jackbedford/Desktop/MOXA/Code/data/2023-09-12-2/UDP_Bandlock_9S_Phone_Brown/sm00/#01/data/diag_log_sm00_2023-09-12_13-34-15_nr_ml1.csv']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepaths = filepaths[0:1]\n",
    "filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = Profile(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dl_lost': {'LTEH': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'ENBH': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'MCGH': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'MNBH': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGM': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGA': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGR-I': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGR-II': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGC-I': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGC-II': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGF': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'MCGF': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'NASR': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'Stable': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []}},\n",
       " 'dl_excl': {'LTEH': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'ENBH': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'MCGH': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'MNBH': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGM': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGA': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGR-I': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGR-II': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGC-I': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGC-II': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGF': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'MCGF': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'NASR': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'Stable': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []}},\n",
       " 'ul_lost': {'LTEH': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'ENBH': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'MCGH': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'MNBH': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGM': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGA': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGR-I': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGR-II': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGC-I': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGC-II': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGF': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'MCGF': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'NASR': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'Stable': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []}},\n",
       " 'ul_excl': {'LTEH': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'ENBH': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'MCGH': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'MNBH': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGM': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGA': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGR-I': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGR-II': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGC-I': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGC-II': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'SCGF': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'MCGF': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'NASR': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []},\n",
       "  'Stable': {'dist_table': [],\n",
       "   'relative_loex_timestamp': [],\n",
       "   'relative_timestamp': [],\n",
       "   'interruption_time': [],\n",
       "   'trigger_loex': [],\n",
       "   'event_count': []}}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moxa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
